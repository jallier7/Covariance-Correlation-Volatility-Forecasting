{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "import seaborn as sns\n",
    "from cvx.covariance.combination import from_ewmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble des librairies utilis√©es\n",
    "from xbbg import blp\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from pylatex import Document, Section, Subsection, Math, Table, Tabular, Figure, Command, MiniPage\n",
    "from pylatex.utils import NoEscape\n",
    "import subprocess\n",
    "from pylatex.utils import bold\n",
    "from pylatex.package import Package\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Covariance-Correlation-Volatility-Forecasting\\SP500_daily_returns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6224, 355)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_counts=df.isna().sum()\n",
    "columns_to_keep = nan_counts[nan_counts <= 3].index\n",
    "returns = df[columns_to_keep]\n",
    "returns=returns.dropna()\n",
    "returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=returns['Date']\n",
    "returns=returns.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_cov(df, date, window):\n",
    "    cov=np.zeros((len(df.columns),len(df.columns)))\n",
    "    for i in range(date-window, date):\n",
    "        cov+=np.outer(np.array(df.iloc[i,:]),np.array(df.iloc[i,:]))/(window)\n",
    "    covs=pd.DataFrame(cov*250, columns=df.columns, index=df.columns)\n",
    "    return(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_cov(df, date, window, beta):\n",
    "    cov=np.zeros((len(df.columns),len(df.columns)))\n",
    "    for i in range(date-window, date):\n",
    "        cov=(beta)*cov+(1-beta)*np.outer(np.array(df.iloc[i,:]),np.array(df.iloc[i,:]))\n",
    "    covs=pd.DataFrame(cov*250, columns=df.columns, index=df.columns)\n",
    "    return(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "halflife_pairs=[(10, 21), (21, 63), (63, 125)]\n",
    "def ewma_cov(df, date, halflife_pairs, window):    \n",
    "    combinator = from_ewmas(df.iloc[max(0,date-1000):date,:],\n",
    "                                halflife_pairs,\n",
    "                                min_periods_vola=window,  # min periods for volatility estimation\n",
    "                                min_periods_cov=window)  # min periods for correlation estimation\n",
    "\n",
    "    # Solve combination problem and loop through combination results to get predictors\n",
    "    covariance_predictors = {}\n",
    "    for predictor in combinator.solve(window=10):  # lookback window for optimization\n",
    "        # From predictor we can access predictor.time, predictor.mean (=0 here),\n",
    "        # predictor.covariance, and predictor.weights\n",
    "        covariance_predictors[predictor.time] = predictor.covariance\n",
    "    return(covariance_predictors[date]*250)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov=ewma_cov(returns, 3000, halflife_pairs, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AEE</th>\n",
       "      <th>...</th>\n",
       "      <th>WM</th>\n",
       "      <th>WMB</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WRB</th>\n",
       "      <th>WST</th>\n",
       "      <th>WY</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBRA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.307492</td>\n",
       "      <td>0.081876</td>\n",
       "      <td>0.061632</td>\n",
       "      <td>0.084893</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>0.125311</td>\n",
       "      <td>0.124871</td>\n",
       "      <td>0.103233</td>\n",
       "      <td>0.202491</td>\n",
       "      <td>0.081147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>0.149825</td>\n",
       "      <td>0.048280</td>\n",
       "      <td>0.099817</td>\n",
       "      <td>0.131699</td>\n",
       "      <td>0.157546</td>\n",
       "      <td>0.065906</td>\n",
       "      <td>0.102532</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>0.146915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.081876</td>\n",
       "      <td>0.081877</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.032875</td>\n",
       "      <td>0.058121</td>\n",
       "      <td>0.051016</td>\n",
       "      <td>0.051185</td>\n",
       "      <td>0.042361</td>\n",
       "      <td>0.088958</td>\n",
       "      <td>0.031990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>0.067595</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.036287</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.056530</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>0.042743</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.059730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>0.061632</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.037423</td>\n",
       "      <td>0.024934</td>\n",
       "      <td>0.036210</td>\n",
       "      <td>0.031578</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.034649</td>\n",
       "      <td>0.050776</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033782</td>\n",
       "      <td>0.041955</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.028657</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.043766</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.033440</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>0.039716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGL</th>\n",
       "      <td>0.084893</td>\n",
       "      <td>0.032875</td>\n",
       "      <td>0.024934</td>\n",
       "      <td>0.069624</td>\n",
       "      <td>0.053126</td>\n",
       "      <td>0.043499</td>\n",
       "      <td>0.052463</td>\n",
       "      <td>0.044552</td>\n",
       "      <td>0.075387</td>\n",
       "      <td>0.040425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.059805</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.052736</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.042798</td>\n",
       "      <td>0.037545</td>\n",
       "      <td>0.059023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADBE</th>\n",
       "      <td>0.136760</td>\n",
       "      <td>0.058121</td>\n",
       "      <td>0.036210</td>\n",
       "      <td>0.053126</td>\n",
       "      <td>0.140532</td>\n",
       "      <td>0.080936</td>\n",
       "      <td>0.071426</td>\n",
       "      <td>0.066997</td>\n",
       "      <td>0.143927</td>\n",
       "      <td>0.050337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064961</td>\n",
       "      <td>0.084565</td>\n",
       "      <td>0.031220</td>\n",
       "      <td>0.066686</td>\n",
       "      <td>0.075519</td>\n",
       "      <td>0.092044</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.062030</td>\n",
       "      <td>0.057760</td>\n",
       "      <td>0.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>0.157546</td>\n",
       "      <td>0.056530</td>\n",
       "      <td>0.043766</td>\n",
       "      <td>0.056108</td>\n",
       "      <td>0.092044</td>\n",
       "      <td>0.088986</td>\n",
       "      <td>0.089490</td>\n",
       "      <td>0.073103</td>\n",
       "      <td>0.134971</td>\n",
       "      <td>0.055620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067337</td>\n",
       "      <td>0.104776</td>\n",
       "      <td>0.036961</td>\n",
       "      <td>0.072080</td>\n",
       "      <td>0.087510</td>\n",
       "      <td>0.156827</td>\n",
       "      <td>0.045022</td>\n",
       "      <td>0.074702</td>\n",
       "      <td>0.064750</td>\n",
       "      <td>0.097644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XEL</th>\n",
       "      <td>0.065906</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.034999</td>\n",
       "      <td>0.044462</td>\n",
       "      <td>0.036461</td>\n",
       "      <td>0.054729</td>\n",
       "      <td>0.039986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038138</td>\n",
       "      <td>0.049792</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.037237</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.045022</td>\n",
       "      <td>0.037015</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.044260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.102532</td>\n",
       "      <td>0.042743</td>\n",
       "      <td>0.033440</td>\n",
       "      <td>0.042798</td>\n",
       "      <td>0.062030</td>\n",
       "      <td>0.058953</td>\n",
       "      <td>0.070965</td>\n",
       "      <td>0.054311</td>\n",
       "      <td>0.089435</td>\n",
       "      <td>0.044139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060272</td>\n",
       "      <td>0.085821</td>\n",
       "      <td>0.028190</td>\n",
       "      <td>0.051829</td>\n",
       "      <td>0.061383</td>\n",
       "      <td>0.074702</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.076495</td>\n",
       "      <td>0.044778</td>\n",
       "      <td>0.074227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>0.094296</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>0.037545</td>\n",
       "      <td>0.057760</td>\n",
       "      <td>0.051824</td>\n",
       "      <td>0.054226</td>\n",
       "      <td>0.046694</td>\n",
       "      <td>0.080789</td>\n",
       "      <td>0.037829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045413</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.045548</td>\n",
       "      <td>0.054223</td>\n",
       "      <td>0.064750</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.044778</td>\n",
       "      <td>0.077794</td>\n",
       "      <td>0.061580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>0.146915</td>\n",
       "      <td>0.059730</td>\n",
       "      <td>0.039716</td>\n",
       "      <td>0.059023</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.086309</td>\n",
       "      <td>0.086164</td>\n",
       "      <td>0.069190</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.056873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070448</td>\n",
       "      <td>0.106707</td>\n",
       "      <td>0.035450</td>\n",
       "      <td>0.069018</td>\n",
       "      <td>0.081501</td>\n",
       "      <td>0.097644</td>\n",
       "      <td>0.044260</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.061580</td>\n",
       "      <td>0.145901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354 rows √ó 354 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A      AAPL       ABT      ACGL      ADBE       ADI       ADM  \\\n",
       "A     0.307492  0.081876  0.061632  0.084893  0.136760  0.125311  0.124871   \n",
       "AAPL  0.081876  0.081877  0.020323  0.032875  0.058121  0.051016  0.051185   \n",
       "ABT   0.061632  0.020323  0.037423  0.024934  0.036210  0.031578  0.039333   \n",
       "ACGL  0.084893  0.032875  0.024934  0.069624  0.053126  0.043499  0.052463   \n",
       "ADBE  0.136760  0.058121  0.036210  0.053126  0.140532  0.080936  0.071426   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "WY    0.157546  0.056530  0.043766  0.056108  0.092044  0.088986  0.089490   \n",
       "XEL   0.065906  0.023848  0.025365  0.031683  0.039625  0.034999  0.044462   \n",
       "XOM   0.102532  0.042743  0.033440  0.042798  0.062030  0.058953  0.070965   \n",
       "YUM   0.094296  0.043067  0.030317  0.037545  0.057760  0.051824  0.054226   \n",
       "ZBRA  0.146915  0.059730  0.039716  0.059023  0.089100  0.086309  0.086164   \n",
       "\n",
       "           ADP      ADSK       AEE  ...        WM       WMB       WMT  \\\n",
       "A     0.103233  0.202491  0.081147  ...  0.106054  0.149825  0.048280   \n",
       "AAPL  0.042361  0.088958  0.031990  ...  0.040080  0.067595  0.017952   \n",
       "ABT   0.034649  0.050776  0.029607  ...  0.033782  0.041955  0.019628   \n",
       "ACGL  0.044552  0.075387  0.040425  ...  0.048268  0.059805  0.024008   \n",
       "ADBE  0.066997  0.143927  0.050337  ...  0.064961  0.084565  0.031220   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "WY    0.073103  0.134971  0.055620  ...  0.067337  0.104776  0.036961   \n",
       "XEL   0.036461  0.054729  0.039986  ...  0.038138  0.049792  0.020169   \n",
       "XOM   0.054311  0.089435  0.044139  ...  0.060272  0.085821  0.028190   \n",
       "YUM   0.046694  0.080789  0.037829  ...  0.045413  0.067020  0.025365   \n",
       "ZBRA  0.069190  0.134133  0.056873  ...  0.070448  0.106707  0.035450   \n",
       "\n",
       "           WRB       WST        WY       XEL       XOM       YUM      ZBRA  \n",
       "A     0.099817  0.131699  0.157546  0.065906  0.102532  0.094296  0.146915  \n",
       "AAPL  0.036287  0.045181  0.056530  0.023848  0.042743  0.043067  0.059730  \n",
       "ABT   0.028657  0.036958  0.043766  0.025365  0.033440  0.030317  0.039716  \n",
       "ACGL  0.060166  0.052736  0.056108  0.031683  0.042798  0.037545  0.059023  \n",
       "ADBE  0.066686  0.075519  0.092044  0.039625  0.062030  0.057760  0.089100  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "WY    0.072080  0.087510  0.156827  0.045022  0.074702  0.064750  0.097644  \n",
       "XEL   0.037237  0.037276  0.045022  0.037015  0.036697  0.030930  0.044260  \n",
       "XOM   0.051829  0.061383  0.074702  0.036697  0.076495  0.044778  0.074227  \n",
       "YUM   0.045548  0.054223  0.064750  0.030930  0.044778  0.077794  0.061580  \n",
       "ZBRA  0.069018  0.081501  0.097644  0.044260  0.074227  0.061580  0.145901  \n",
       "\n",
       "[354 rows x 354 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cov_Models:\n",
    "    def __init__(self, df, annualization):\n",
    "        self.df = df\n",
    "        self.annualization = annualization \n",
    "    def histo_cov(self, window):\n",
    "        if window == 1:\n",
    "            # Approxime la covariance en utilisant le produit des rendements pour chaque paire d'actifs\n",
    "            cov_matrix = pd.DataFrame(index=self.df.columns, columns=self.df.columns)\n",
    "            for col1 in self.df.columns:\n",
    "                for col2 in self.df.columns:\n",
    "                    cov_matrix.loc[col1, col2] = self.df.iloc[-1][col1] * self.df.iloc[-1][col2] * self.annualization\n",
    "        else:\n",
    "            # Calcul standard de la covariance sur la fen√™tre d√©finie\n",
    "            cov_matrix = self.df.iloc[len(self.df.index) - window:len(self.df.index), :].cov() * self.annualization\n",
    "\n",
    "        return cov_matrix\n",
    "    \n",
    "    def EWMA_series(self,beta, actif1,actif2):\n",
    "        ewma_cov=0\n",
    "        m1 = max(self.df.loc[:, actif1].first_valid_index(), self.df.loc[:, actif2].first_valid_index())\n",
    "        while self.df.loc[m1:, actif1].isna().any() or self.df.loc[m1:, actif2].isna().any():\n",
    "            m1+=1\n",
    "        for t in range(m1,len(self.df.index)):\n",
    "            r_t1 = self.df.loc[t,actif1]\n",
    "            r_t2 = self.df.loc[t,actif2]\n",
    "            ewma_cov=beta*ewma_cov+(1-beta)* r_t1*r_t2\n",
    "        ewma_cov=ewma_cov*self.annualization\n",
    "        return (ewma_cov)\n",
    "    def EWMA_cov_opti(self, actif1,actif2, horizon):\n",
    "        betas = np.linspace(0.90, 0.99, 21)\n",
    "        covs = [[] for _ in range(len(betas))]\n",
    "        score= [[] for _ in range(len(betas))]\n",
    "        for j, beta in enumerate(betas):\n",
    "            cov_realized = []\n",
    "            for t in range(len(self.df.index)-100-horizon,len(self.df.index)-horizon, 10):\n",
    "                realized=0\n",
    "                for j in range(horizon):\n",
    "                    realized+= self.df.loc[t+j:t + j, actif1]* self.df.loc[t+j:t + j, actif2] * self.annualization\n",
    "                cov_realized.append(realized)\n",
    "                covs[j].append(self.EWMA_series(beta, actif1,actif2))\n",
    "            score[j]=np.sum((np.array(cov_realized)-np.array(covs[j]))**2)\n",
    "        beta_opt=betas[score.index(min(score))]\n",
    "        return(beta_opt)\n",
    "    def EWMA_cov(self, beta_var, beta_cov, horizon):\n",
    "        ewma_cov=[]\n",
    "        pairs=[]\n",
    "        for j in range(len(self.df.columns)):\n",
    "            for i in range(j, len(self.df.columns)):\n",
    "                pairs.append((self.df.columns[j], self.df.columns[i]))\n",
    "        for j, (actif1, actif2) in enumerate (pairs):\n",
    "            if beta_var=='Opti' and beta_cov=='Opti':\n",
    "                ewma_cov.append(self.EWMA_series(self.EWMA_cov_opti( actif1,actif2, horizon), actif1,actif2))\n",
    "            else:\n",
    "                if actif1==actif2:\n",
    "                    ewma_cov.append(self.EWMA_series(beta_var, actif1,actif2))\n",
    "                else:\n",
    "                    ewma_cov.append(self.EWMA_series(beta_cov, actif1,actif2))\n",
    "        covs=np.zeros((len(self.df.columns),len(self.df.columns)))\n",
    "        k=0\n",
    "        for j in range(len(self.df.columns)):\n",
    "            for i in range(j, len(self.df.columns)):\n",
    "                covs[j,i]=covs[i,j]=ewma_cov[k]\n",
    "                k+=1\n",
    "        covariance=pd.DataFrame(covs, columns=self.df.columns, index=self.df.columns)\n",
    "        return covariance\n",
    "    \n",
    "    def HAR_cov(self, windows_var, windows_cov, horizon):\n",
    "        Har_covs = []\n",
    "        pairs = []\n",
    "        for j in range(len(self.df.columns)):\n",
    "            for i in range(j, len(self.df.columns)):\n",
    "                pairs.append((self.df.columns[j], self.df.columns[i]))\n",
    "        for actif1, actif2 in pairs:\n",
    "            m1 = max(self.df.loc[:, actif1].first_valid_index(), self.df.loc[:, actif2].first_valid_index())\n",
    "            while self.df.loc[m1:, actif1].isna().any() or self.df.loc[m1:, actif2].isna().any():\n",
    "                m1 += 1\n",
    "            if actif1 == actif2:\n",
    "                windows = windows_var\n",
    "            else:\n",
    "                windows = windows_cov\n",
    "            covs = [[] for _ in range(len(windows))]\n",
    "            cov_realized = []\n",
    "            for t in range(max(max(windows[-1], m1),len(self.df.index) - 250),  len(self.df.index) - horizon):\n",
    "                for i, window in enumerate(windows):\n",
    "                    if window > 1:\n",
    "                        cov_value = self.df.loc[t - window:t - 1, [actif1, actif2]].cov().iloc[0, 1] * self.annualization\n",
    "                    else:\n",
    "                        # Calcul de covariance pour une fen√™tre de taille 1\n",
    "                        cov_value = self.df.loc[t - 1, actif1] * self.df.loc[t - 1, actif2] * self.annualization\n",
    "                    covs[i].append(cov_value)\n",
    "\n",
    "                # Calcul pour cov_realized\n",
    "                if horizon > 1:\n",
    "                    cov_realized_value = self.df.loc[t:t + horizon, [actif1, actif2]].cov().iloc[0, 1] * self.annualization\n",
    "                else:\n",
    "                    cov_realized_value = self.df.loc[t, actif1] * self.df.loc[t, actif2] * self.annualization\n",
    "                cov_realized.append(cov_realized_value)\n",
    "\n",
    "            cov_data = pd.DataFrame({f'cov_{i+1}': covs[i] for i in range(len(windows))})\n",
    "            cov_data['cov_realized'] = cov_realized\n",
    "            cov_data = cov_data.dropna()\n",
    "\n",
    "            X = cov_data[[f'cov_{i+1}' for i in range(len(windows))]]\n",
    "            X = add_constant(X)\n",
    "            y = cov_data['cov_realized']\n",
    "            model = OLS(y, X).fit()\n",
    "            latest_covs = {'intercept': [1]}\n",
    "            for i, window in enumerate(windows):\n",
    "                if window > 1:\n",
    "                    latest_cov_value = self.df.loc[len(self.df.index) - window:len(self.df.index) - 1, [actif1, actif2]].cov().iloc[0, 1] * self.annualization\n",
    "                else:\n",
    "                    latest_cov_value = self.df.loc[len(self.df.index) - 1, actif1] * self.df.loc[len(self.df.index) - 1, actif2] * self.annualization\n",
    "                latest_covs[f'cov_{i+1}'] = [latest_cov_value]\n",
    "\n",
    "            lastest_data = pd.DataFrame(latest_covs)\n",
    "            cov_forecast = model.predict(lastest_data)\n",
    "            Har_covs.append(cov_forecast.iloc[0])\n",
    "            if progress_bar:  # Update the progress bar if provided\n",
    "                progress_bar.update(1)\n",
    "        covs = np.zeros((len(self.df.columns), len(self.df.columns)))\n",
    "        k = 0\n",
    "        for j in range(len(self.df.columns)):\n",
    "            for i in range(j, len(self.df.columns)):\n",
    "                covs[j, i] = covs[i, j] = Har_covs[k]\n",
    "                k += 1\n",
    "        covariance = pd.DataFrame(covs, columns=self.df.columns, index=self.df.columns)\n",
    "        return covariance\n",
    "        \n",
    "    def timeseries_to_supervised(self, data, lag=1):\n",
    "        supervised_data = pd.DataFrame(data)\n",
    "        columns = [supervised_data.shift(i) for i in range(1, lag+1)]\n",
    "        columns.append(supervised_data)\n",
    "        supervised_data = pd.concat(columns, axis=1)\n",
    "        supervised_data.fillna(0, inplace=True)\n",
    "        supervised_data = supervised_data[2:].reset_index(drop=True)\n",
    "        return supervised_data\n",
    "\n",
    "    def fit_lstm(self, X, y, batch_size, nb_epoch, neurons):\n",
    "        # Define the model with the preferred Input(shape) object\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(X.shape[1], X.shape[2])))  # Using Input layer to define input shape\n",
    "        model.add(LSTM(neurons))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        # Fit the model\n",
    "        for _ in range(nb_epoch):\n",
    "            model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def LSTM_cov(self,  batch_size, nb_epoch, neurons, horizon):\n",
    "        cov = []\n",
    "        pairs=[]\n",
    "        Stationnary={}\n",
    "        for actif in self.df.columns:\n",
    "            rendements=self.df.loc[:,actif]\n",
    "            m1=rendements.first_valid_index()\n",
    "            while rendements.iloc[m1:].isna().any():\n",
    "                m1+=1\n",
    "            y=rendements.iloc[m1:]\n",
    "            adf_result = adfuller(y)\n",
    "            if adf_result[1]>=0.05:\n",
    "                Stationnary[actif]=False\n",
    "            else:\n",
    "                Stationnary[actif]=True\n",
    "        k=0\n",
    "        for j in range(len(self.df.columns)):\n",
    "            for i in range(j, len(self.df.columns)):\n",
    "                k+=1\n",
    "                pairs.append((self.df.columns[j], self.df.columns[i]))\n",
    "        k=0\n",
    "        for actif1, actif2 in pairs:\n",
    "            if Stationnary[actif1]==False or Stationnary[actif2]==False:\n",
    "                cov.append(self.df.loc[len(self.df.index)-horizon*self.annualization:len(self.df.index), [actif1,actif2]].cov().iloc[0,1] * self.annualization)\n",
    "            else:\n",
    "                m1 = max(self.df.loc[:, actif1].first_valid_index(), self.df.loc[:, actif2].first_valid_index())\n",
    "                while self.df.loc[m1:, actif1].isna().any() or self.df.loc[m1:, actif2].isna().any():\n",
    "                    m1+=1\n",
    "                constante1 = self.df.loc[0:len(self.df.index)-96, [actif1,actif2]].cov().iloc[0,1] * self.annualization\n",
    "                constante2 = self.df.loc[len(self.df.index)-96:len(self.df.index), [actif1,actif2]].cov().iloc[0,1] * self.annualization\n",
    "                high = max(constante1, constante2)\n",
    "                low = min(constante1, constante2)\n",
    "\n",
    "                if horizon == 1:\n",
    "                    if (high - low) / low >= 0.3:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(len(self.df.index)-108, m1), len(self.df.index), 6)])\n",
    "                    else:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(m1, 5), len(self.df.index), 6)])\n",
    "                        ind_to_remove = np.argsort(X)[-4:]\n",
    "                        mask = np.ones(len(X), dtype=bool)\n",
    "                        mask[ind_to_remove] = False\n",
    "                        X = X[mask]\n",
    "                elif horizon == 3:\n",
    "                    if (high - low) / low >= 0.3:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(len(self.df.index)-144, m1), len(self.df.index), 6)])\n",
    "                    else:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(m1, 5), len(self.df.index), 6)])\n",
    "                        ind_to_remove = np.argsort(X)[-3:]\n",
    "                        mask = np.ones(len(X), dtype=bool)\n",
    "                        mask[ind_to_remove] = False\n",
    "                        X = X[mask]\n",
    "                elif horizon == 5 or horizon == 7:\n",
    "                    if (high - low) / low >= 0.3:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(len(self.df.index)-180, m1), len(self.df.index), 6)])\n",
    "                    else:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(m1, 5), len(self.df.index), 6)])\n",
    "                        ind_to_remove = np.argsort(X)[-2:]\n",
    "                        mask = np.ones(len(X), dtype=bool)\n",
    "                        mask[ind_to_remove] = False\n",
    "                        X = X[mask]\n",
    "                elif horizon == 10:\n",
    "                    if (high - low) / low >= 0.3:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(len(self.df.index)-240, m1), len(self.df.index), 6)])\n",
    "                    else:\n",
    "                        X = np.array([self.df.loc[t-5:t, [actif1,actif2]].cov().iloc[0,1] * self.annualization for t in range(max(m1, 5), len(self.df.index), 6)])\n",
    "                        ind_to_remove = np.argsort(X)[-1:]\n",
    "                        mask = np.ones(len(X), dtype=bool)\n",
    "                        mask[ind_to_remove] = False\n",
    "                        X = X[mask]\n",
    "\n",
    "                X = X.reshape(len(X), 1)\n",
    "                scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "                scaler = scaler.fit(X)\n",
    "                scaled_X = scaler.transform(X)\n",
    "                train = self.timeseries_to_supervised(scaled_X, lag=1)\n",
    "                values = train.values\n",
    "                X, y = values[:, 0].reshape(-1, 1), values[:, 1].reshape(-1, 1)\n",
    "                X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "                model = self.fit_lstm(X, y, batch_size, nb_epoch, neurons)\n",
    "                cov_forecast = model.predict(X, batch_size=1)\n",
    "                cov.append(scaler.inverse_transform(cov_forecast)[:2*horizon, 0].mean())\n",
    "                k+=1\n",
    "                if progress_bar:  # Update the progress bar if provided\n",
    "                    progress_bar.update(1)\n",
    "        covs=np.zeros((len(self.df.columns),len(self.df.columns)))\n",
    "        k=0\n",
    "        for j in range(len(self.df.columns)):\n",
    "            for i in range(j, len(self.df.columns)):\n",
    "                covs[j,i]=covs[i,j]=cov[k]\n",
    "                k+=1\n",
    "                \n",
    "        covariance=pd.DataFrame(covs, columns=self.df.columns, index=self.df.columns)\n",
    "        volatilities = np.sqrt(np.diag(covariance))\n",
    "\n",
    "        # Parcourir chaque √©l√©ment de la matrice\n",
    "        for i in range(covariance.shape[0]):\n",
    "            for j in range(covariance.shape[1]):\n",
    "                # Calculer le produit des volatilit√©s correspondantes\n",
    "                vol_product = volatilities[i] * volatilities[j]\n",
    "                # V√©rifier si la covariance est sup√©rieure au produit des volatilit√©s\n",
    "                if covariance.iloc[i, j] > vol_product:\n",
    "                    # Remplacer la valeur par le produit des volatilit√©s\n",
    "                    covariance.iloc[i, j] = vol_product\n",
    "        return covariance\n",
    "\n",
    "    def volatilite(self, covariance):\n",
    "        vol=[]\n",
    "        for i in range(covariance.shape[0]):\n",
    "            vol.append(np.sqrt(covariance.iloc[i,i]))\n",
    "        return(np.array(vol))\n",
    "    \n",
    "    def correlation(self, covariance):\n",
    "        correl= np.zeros((covariance.shape[0],covariance.shape[0]))\n",
    "        vol=self.volatilite(covariance)\n",
    "        for i in range(covariance.shape[0]):\n",
    "            for j in range(covariance.shape[1]):\n",
    "                correl[i,j]=covariance.iloc[i,j]/(vol[i]*vol[j])\n",
    "        return(pd.DataFrame(correl, columns=self.df.columns, index=self.df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
